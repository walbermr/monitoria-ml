{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Índice\n",
    "\n",
    "1. [Importando bibliotecas](#importando-bibliotecas)\n",
    "2. [Treinamento do modelo](#treinamento-do-modelo)\n",
    "3. [Melhorando o modelo](#melhorando-o-modelo)\n",
    "4. [Um dataset mais complicado](#um-dataset-mais-complicado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas de manipualção e visualização de dados\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "# Classes do modelo\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Funções de avaliação dos modelos\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Função para carregar nosso dataset\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "def show_decision_region(x, y, clf, f0, f1):\n",
    "    plot_decision_regions(x, y, clf=clf)\n",
    "    plt.xlabel(f0)\n",
    "    plt.ylabel(f1)\n",
    "    if clf.__class__.__name__ == \"KNeighborsClassifier\":\n",
    "        plt.title(clf.__class__.__name__ + \" k = \" + str(clf.n_neighbors))\n",
    "    else:\n",
    "        plt.title(clf.__class__.__name__)\n",
    "    plt.show()\n",
    "\n",
    "# criar uma função \n",
    "def show_dataset(x, y):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos estudar a implementação do MLP no sklearn. Primeiro, o MLPClassifier treina iterativamente, já que em cada passo de otimização, as derivadas parciais da função de custo (loss function) em relação aos parâmetros da rede (pesos e bias de cada camada) são calculadas. \n",
    "\n",
    "Alguns parâmetros importantes no MLP:\n",
    " \n",
    "- hidden_layer_sizes: Tupla que controla a profundidade (quantidade de camadas) e números de neurônios na por cada camada escondida. Por exemplo: (100, 10,) cria uma rede com 100 neuronios na primeira camada escondida e 10 na segunda camada. O número de neurônios na entrada da rede é o número de features. A saída da ultima camada escondida tem o tamanho da quantidade de classes ou dimensões (regressão).\n",
    "- activation: Define {‘identity’, ‘logistic’, ‘tanh’, ‘relu’} funções de ativação.\n",
    "    - identity: $f(x) = x$\n",
    "    - logistic: $1 / (1 + e^{-x})$\n",
    "    - tanh: $tanh(x)$\n",
    "    - relu: $max(0, x)$\n",
    "- batch_size: default=’auto’ Tamanho do batch de treinamento, se for mantido em \"auto\", $batch_size=min(200, n\\_samples)$.\n",
    "- learning_rate: default=’constant’ Esquema de redução de _learning_rate_. Caso seja constante, a mesma _learning_rate_ no início do treino segue até o fim.\n",
    "- max_iter: default=200 Número máximo de iterações, caso o modelo não atinja convergência.\n",
    "- tol: Caso a função de custo no treinamento não melhorar mais do que _tol_, é considerado que o modelo atingiu convergência.\n",
    "- early_stopping: default=False Se esse parâmetro for verdadeiro, separa automaticamente uma fração do dataset de treino em um dataset de validação, de tamanho validation_fraction_.\n",
    "- validation_fraction: default=0.1, representando 10% do dataset para validação.\n",
    "- n_iter_no_change default=10 Número máximo de épocas em que o algoritmo deve parar caso não melhore mais que _tol_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregar dataset\n",
    "X, y = load_wine(return_X_y=True, as_frame=True)\n",
    "\n",
    "# definição de classes e features\n",
    "class_a = 0\n",
    "class_b = 1\n",
    "feature_0 = \"alcohol\"\n",
    "feature_1 = \"color_intensity\"\n",
    "\n",
    "# filtrar classes e features\n",
    "class_0_instances = (y == class_a)\n",
    "class_1_instances = (y == class_b)\n",
    "\n",
    "filtered_y = y[class_0_instances | class_1_instances]\n",
    "filtered_X = X[class_0_instances | class_1_instances]\n",
    "filtered_X = filtered_X[[feature_0, feature_1]]\n",
    "\n",
    "# dividir classificador em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(filtered_X[[feature_0, feature_1]], filtered_y, test_size=0.3, random_state=199)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=199)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a = MLPClassifier(random_state=199)\n",
    "model_a.fit(X_train, y_train)\n",
    "\n",
    "show_decision_region(\n",
    "    np.array(\n",
    "        [\n",
    "            X_val[feature_0].values, \n",
    "            X_val[feature_1].values,\n",
    "        ]\n",
    "    ).T, \n",
    "    y_val.values, \n",
    "    model_a, \n",
    "    feature_0, \n",
    "    feature_1\n",
    ")\n",
    "\n",
    "print(classification_report(y_val, model_a.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# como se comportou o treinamento do modelo?\n",
    "plt.plot(model.loss_curve_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O que podemos fazer para melhorar _model_a_? \n",
    "\n",
    "É possível criar um [pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) de objetos que podem auxiliar nosso classificador, como [preprocessamento](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing). Um pipeline é criado com uma lista de transformações e um classificador, que tem como propósito agregar vários passos em apenas um objeto, deixando transparente que tipo de processamento é realizado.\n",
    "\n",
    "Alguns modelos de [preprocessamento](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing):\n",
    "\n",
    "Standard Scaler: $Z = \\frac{X-\\mu}{\\sigma}$\n",
    "\n",
    "Min-max Scaler: $\\frac{X-min(X)}{max(X) - min(X)}$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_val, model_a.predict(X_val)))\n",
    "print(classification_report(y_val, model_b.predict(X_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Um dataset mais complicado\n",
    "\n",
    "Agora que já vimos algumas características do MLP no dataset que já conhecemos, como podemos resolver um desafio maior?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# criação do dataset\n",
    "X, y = make_moons(n_samples=900, noise=0.2, random_state=199)\n",
    "\n",
    "# cores e simbolos para as classses\n",
    "colors = {0: \"steelblue\", 1: \"darkorange\", 2: \"mediumseagreen\"}\n",
    "markers = {0: \"s\", 1: \"^\", 2:\"o\"}\n",
    "\n",
    "# visualização do dataset\n",
    "plt.scatter(\n",
    "    X[y==0, 0],\n",
    "    X[y==0, 1], \n",
    "    c=colors[0], \n",
    "    marker=markers[0]\n",
    ")\n",
    "plt.scatter(\n",
    "    X[y==1, 0], \n",
    "    X[y==1, 1], \n",
    "    c=colors[1], \n",
    "    marker=markers[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos classificar esse dataset usando um MLP"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2740ff0ff5ab647f4caa51cae9634c8f0b586b6f57486f90b97d87d738fcb59"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('mscenv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
